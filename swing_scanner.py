# -*- coding: utf-8 -*-
"""Swing_Scanner.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17MW6_Rd7vdubp2GucNKFKdLUuwratV-W
"""

# Install deps (run once per new runtime)

import os
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID", "")

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from ta.trend import SMAIndicator
from scipy.stats import linregress
import requests

pd.options.display.float_format = '{:,.2f}'.format

# === Scanner Settings (you can tweak later) ===
UNIVERSE = "S&P500"  # "S&P500" or "Custom List"

LOOKBACK_MONTHS_RS = 6   # RS lookback
ADR_PERIOD = 14
MA_PERIOD = 22
AVG_VOL_LOOKBACK = 30

# Consolidation detection
CONS_LOOKBACK = 15
MAX_RANGE_PCT = 12.0
REQUIRE_LOWER_HIGHS_HIGHER_LOWS = True
BREAKOUT_BUFFER_PCT = 0.3  # % above recent high to call breakout

# Risk per trade (example)
MAX_RISK_DOLLARS = 500

# Telegram (optional) â€” leave blank to skip alerts
TELEGRAM_BOT_TOKEN = ""   # e.g. 123456:ABCDEF...
TELEGRAM_CHAT_ID = ""     # e.g. your chat id

def get_universe(universe="S&P500", custom=None):
    if universe == "S&P500":
        tables = pd.read_html("https://en.wikipedia.org/wiki/List_of_S%26P_500_companies")
        tickers = tables[0]["Symbol"].tolist()
        tickers = [t.replace('.', '-') for t in tickers]  # yfinance style
        return sorted(list(set(tickers)))
    elif universe == "Custom List":
        return custom or []
    return []

def compute_adr(df, period=14):
    dr = df['High'] - df['Low']
    return dr.rolling(period).mean()

def rs_percentile(tickers, months=6, benchmark='SPY'):
    bench = yf.download(benchmark, period=f"{months*32}d", interval="1d", progress=False)['Close'].dropna()
    results = {}
    for t in tickers:
        try:
            px = yf.download(t, period=f"{months*32}d", interval="1d", progress=False)['Close'].dropna()
            if len(px) < 20:
                continue
            r_stock = (px.iloc[-1] / px.iloc[0]) - 1
            bench_sync = bench.reindex(px.index, method='ffill')
            r_bench = (bench_sync.iloc[-1] / bench_sync.iloc[0]) - 1
            results[t] = r_stock - r_bench
        except Exception:
            pass
    ser = pd.Series(results)
    return ser.rank(pct=True)  # 0..1

def check_consolidation_and_breakout(df, lookback=15, max_range_pct=12.0,
                                     require_triangle=True, breakout_buffer_pct=0.3):
    if len(df) < lookback + 2:
        return False, False, np.nan, np.nan

    window = df.iloc[-lookback:]
    hi = window['High'].values
    lo = window['Low'].values
    close = df['Close'].iloc[-1]
    high_recent = hi.max()
    low_recent = lo.min()

    rng_pct = (high_recent - low_recent) / max(1e-9, close) * 100.0
    tight = rng_pct <= max_range_pct

    triangle_ok = True
    if require_triangle:
        x = np.arange(len(window))
        slope_high = linregress(x, hi).slope
        slope_low  = linregress(x, lo).slope
        triangle_ok = (slope_high < 0) and (slope_low > 0)

    cons = tight and triangle_ok
    brk = False
    if cons:
        breakout_level = high_recent * (1 + breakout_buffer_pct/100.0)
        brk = df['Close'].iloc[-1] > breakout_level

    return cons, brk, high_recent, low_recent

def position_size(entry, stop, max_risk_dollars=500):
    risk_per_share = max(1e-8, abs(entry - stop))
    qty = int(max_risk_dollars // risk_per_share)
    return max(qty, 0)

def send_telegram_message(token, chat_id, text):
    if not token or not chat_id:
        return None
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    payload = {"chat_id": chat_id, "text": text, "parse_mode": "HTML", "disable_web_page_preview": True}
    try:
        r = requests.post(url, data=payload, timeout=10)
        return r.ok
    except Exception:
        return None

# ===== Step 7 (v2): Run the scanner with robust RS + safe sorting & diagnostics =====

# --- Robust RS percentile (index-aligned to SPY) ---
def rs_percentile(tickers, months=6, benchmark='SPY'):
    bench = yf.download(benchmark, period=f"{months*32}d", interval="1d",
                        auto_adjust=True, progress=False)['Close'].dropna()

    results = {}
    for t in tickers:
        try:
            px = yf.download(t, period=f"{months*32}d", interval="1d",
                             auto_adjust=True, progress=False)['Close'].dropna()
            if len(px) < 20:
                continue
            bench_sync = bench.reindex(px.index).ffill().dropna()
            px = px.reindex(bench_sync.index).ffill().dropna()
            if len(px) < 2 or len(bench_sync) < 2:
                continue
            r_stock = (px.iloc[-1] / px.iloc[0]) - 1
            r_bench = (bench_sync.iloc[-1] / bench_sync.iloc[0]) - 1
            results[t] = float(r_stock - r_bench)
        except Exception:
            pass

    ser = pd.Series(results)
    return ser.rank(pct=True)  # 0..1

# --- Helper: safer yfinance download for single ticker ---
def safe_download(t, period="6mo", interval="1d"):
    try:
        df = yf.download(t, period=period, interval=interval,
                         auto_adjust=False, progress=False)
        if isinstance(df.columns, pd.MultiIndex):
            df = df.swaplevel(axis=1)[t]
        return df.dropna()
    except Exception as e:
        print(f"[download fail] {t}: {e}")
        return pd.DataFrame()

# --- Build universe ---
tickers = get_universe(UNIVERSE, custom=locals().get("CUSTOM_TICKERS"))
print(f"Universe size: {len(tickers)}")

# --- Compute RS percentile (top 2% => >= 0.98) ---
rs_series = rs_percentile(tickers, months=LOOKBACK_MONTHS_RS, benchmark='SPY')
rs_dict = rs_series.to_dict()

# --- Scan loop ---
candidates = []
skips = {"empty":0, "short":0, "price":0, "filters":0}

for t in tickers:
    df = safe_download(t, period="6mo", interval="1d")
    if df.empty:
        skips["empty"] += 1
        continue
    if len(df) < max(MA_PERIOD, ADR_PERIOD) + 2:
        skips["short"] += 1
        continue

    try:
        price = float(df['Close'].iloc[-1])
        if price <= 1:
            skips["price"] += 1
            continue

        adr_val = compute_adr(df, period=ADR_PERIOD).iloc[-1]
        if pd.isna(adr_val):
            continue
        adr_pct = float((adr_val / price) * 100.0)

        avg_vol = float(df['Volume'].rolling(AVG_VOL_LOOKBACK).mean().iloc[-1])

        ma = SMAIndicator(df['Close'], window=MA_PERIOD).sma_indicator().iloc[-1]

        rs = float(rs_dict.get(t, np.nan))
        if np.isnan(rs):
            continue

        passed = (adr_pct > 5) and (avg_vol > 30_000_000) and (price > ma) and (rs >= 0.98)
        if not passed:
            skips["filters"] += 1
            continue

        cons, brk, hi_c, lo_c = check_consolidation_and_breakout(
            df,
            lookback=CONS_LOOKBACK,
            max_range_pct=MAX_RANGE_PCT,
            require_triangle=REQUIRE_LOWER_HIGHS_HIGHER_LOWS,
            breakout_buffer_pct=BREAKOUT_BUFFER_PCT
        )
        dist_ma_pct = (price - ma) / ma * 100.0
        signal = "Breakout" if brk else ("Consolidation" if cons else "")

        candidates.append({
            "Ticker": t,
            "Price": price,
            "ADR%": round(adr_pct, 2),
            "AvgVol(30d)": int(avg_vol),
            "RS_pctile": round(rs, 4),
            f"Dist_{MA_PERIOD}SMA_%": round(dist_ma_pct, 2),
            "Signal": signal
        })
    except Exception as e:
        print(f"[calc error] {t}: {type(e).__name__}: {e}")

# --- Assemble results safely ---
results = pd.DataFrame(candidates)

if results.empty:
    print("No tickers passed all filters today.")
    print("Skipped counts:", skips)
    # Quick diagnostics: show top 15 by RS even if they failed volume/ADR/etc.
    # This helps you see what's close to passing.
    diag = []
    for t in tickers[:300]:  # limit for speed
        try:
            rs = float(rs_dict.get(t, np.nan))
            if np.isnan(rs):
                continue
            df = safe_download(t, period="3mo", interval="1d")
            if df.empty:
                continue
            price = float(df['Close'].iloc[-1])
            adr_val = compute_adr(df, period=ADR_PERIOD).iloc[-1]
            adr_pct = float((adr_val / max(price,1e-9)) * 100.0) if pd.notna(adr_val) else np.nan
            avg_vol = float(df['Volume'].rolling(AVG_VOL_LOOKBACK).mean().iloc[-1]) if 'Volume' in df else np.nan
            diag.append({"Ticker": t, "Price": price, "ADR%": round(adr_pct,2), "AvgVol(30d)": int(avg_vol) if not np.isnan(avg_vol) else np.nan, "RS_pctile": round(rs,4)})
        except Exception:
            pass
    if diag:
        diag_df = pd.DataFrame(diag).sort_values(["RS_pctile"], ascending=False).head(15)
        print("\nTop RS names (for context):")
        display(diag_df)
else:
    results = results.sort_values(
        ["Signal", "RS_pctile", "ADR%"], ascending=[True, False, False]
    ).reset_index(drop=True)
    display(results.head(50))
    print("Skipped counts:", skips)

# Alert to Telegram if there are matches
if 'results' not in globals() or results.empty:
    print("No matches to alert.")
else:
    msg_lines = ["<b>Swing Scanner Matches</b>"]
    for _, r in results.iterrows():
        msg_lines.append(
            f"{r['Ticker']}: ${r['Price']:.2f} | ADR {r['ADR%']:.2f}% | "
            f"RS {r['RS_pctile']:.2f} | DistSMA {r.filter(like='Dist_').iloc[0]:.2f}% | {r['Signal'] or 'â€”'}"
        )
    message = "\n".join(msg_lines)
    ok = send_telegram_message(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, message)
    print("Telegram sent." if ok else "Telegram not configured or failed.")

import getpass

# Hidden input for your bot token
TELEGRAM_BOT_TOKEN = getpass.getpass("Paste your Telegram bot token: ")

# Hidden input for your chat ID
TELEGRAM_CHAT_ID = getpass.getpass("Paste your Telegram chat ID: ")

ok = send_telegram_message(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, "Test: Swing scanner connected âœ…")
print("OK" if ok else "Failed â€” check token/chat ID or start the bot in Telegram.")

# === Send today's matches to Telegram ===
if 'results' not in globals() or results.empty:
    send_telegram_message(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, "ðŸ“‰ No tickers passed all filters today.")
    print("No matches â€” alert sent.")
else:
    msg_lines = ["<b>ðŸ“ˆ Swing Scanner Matches</b>"]
    for _, r in results.iterrows():
        dist_col = [c for c in results.columns if c.startswith("Dist_") and c.endswith("SMA_%")]
        dist_val = r[dist_col[0]] if dist_col else np.nan

        msg_lines.append(
            f"{r['Ticker']}: ${r['Price']:.2f} | ADR {r['ADR%']:.2f}% | "
            f"RS {r['RS_pctile']:.2f} | DistSMA {dist_val:.2f}% | {r['Signal'] or 'â€”'}"
        )

    message = "\n".join(msg_lines)
    ok = send_telegram_message(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, message)
    print("Telegram sent." if ok else "Telegram failed.")

# === Export results to CSV ===
import pandas as pd
from datetime import datetime

if 'results' not in globals() or results.empty:
    print("No matches to export.")
else:
    ts = datetime.now().strftime("%Y%m%d_%H%M")
    filename = f"swing_scanner_{ts}.csv"
    results.to_csv(filename, index=False)
    print(f"Saved {len(results)} results to {filename}")

!pip -q install gspread gspread_dataframe

from google.colab import auth
import gspread
from gspread_dataframe import set_with_dataframe
import google.auth

auth.authenticate_user()
creds, _ = google.auth.default()
gc = gspread.authorize(creds)

sheet_name = "SwingScanner_Results"  # Change if you want
try:
    sh = gc.open(sheet_name)
except gspread.SpreadsheetNotFound:
    sh = gc.create(sheet_name)
    print(f"Created new Google Sheet: {sheet_name}")

# New sheet tab for each run
ts = datetime.now().strftime("%Y%m%d_%H%M")
worksheet = sh.add_worksheet(title=ts, rows="1000", cols="20")
set_with_dataframe(worksheet, results.reset_index(drop=True))
print(f"Wrote {len(results)} rows to Google Sheet: {sheet_name} / {ts}")
if __name__ == "__main__":
    main()
